; SETTINGS FILE FOR FIRST BATCH ON WINDOW CROPPING STRATEGY.



; General project settings
[Project]
; TODO: outsource into database
projectName = The Aerial Elephants Dataset
projectDescription = Elephants and livestock have escaped. Please help us find them!

; Data type. One of {'images', 'map'} (TODO)
dataType = images
; Minimum object side length in pixels. Only used if annotationType is 'boundingBoxes'
minObjSize = 20

; Allow data points not to have a label at all (e.g. for "background" samples)
enableEmptyClass = yes

; Type of annotations the user can provide in the UI. One of {'labels', 'points', 'boundingBoxes'}.
annotationType = boundingBoxes

; Type of annotations the model predicts. Note that this may be different from the "annotationType" property. For example, a setup could have users provide classification labels, but a model predicting points. In this case, "annotationType" would be "classLabels", "predictionType" would be set to "points". Note that this would require translating to usable ground truth in the AI model.
predictionType = boundingBoxes

; Maximum number of images to train model on at a time (otherwise takes latest annotations)
maxNumImages_train = 1024

; Maximum number of images to do inference at a time
maxNumImages_inference = 1024


[UserHandler]
; Maximum login time in seconds
time_login = 600
staticfiles_dir = modules/UserHandling/static
; Secret token required to be allowed to create account.
; Set empty if no restriction required.
create_account_token = PHVKp6aHyMXBEuNJUffjFqS5


; General server settings
[Server]
host = 0.0.0.0
port = 8086

; URL under which the (potentially dedicated) file server can be reached that stores the image data
; Note that this may include the port and static URI of the file server instance.
; For the first, it must correspond to the 'port' entry of this section of the file server's configuration
; file. For the second, it must be identical to the 'staticfiles_uri' entry in section 'FileServer'
; of the file server's configuration file.
dataServer_uri = http://pronghornvm.westus2.cloudapp.azure.com:8086/files


; Properties of the different tiers
[LabelUI]
staticfiles_dir = modules/LabelUI/static


; Properties of the user interface
numImages_x = 3
numImages_y = 2
defaultImage_w = 800
defaultImage_h = 600

; Whether to display model predictions to the user or not
showPredictions = yes
; Minimum confidence for predictions to be displayed
showPredictions_minConf = 0.5

; Carry over the predictions as annotations automatically. If set to yes, every prediction made by the
; model will automatically count as an annotation added (resp. verified) by the user, unless they delete it.
; Notes:
; - If annotationType = labels, the annotation label will be chosen as per the carryOverRule below
; - If predictionType = boundingBoxes and annotationType = points, bounding boxes will be converted to points
; - If predictionType = points and annotationType = boundingBoxes, points will be converted to bounding boxes
;   with default width and height as specified below
; - If carryOverPredictions = no, predictions might be shown (see above), but are immutable
carryOverPredictions = yes
; Minimum confidence for predictions to be considered for carryover
carryOverPredictions_minConf = 0.99

; Rule for prediction carry-over if annotationType = labels and predictionType is vectorial. Modes:
; - maxConfidence: the class of the prediction with the highest confidence will be chosen
; - mode: the most frequently predicted class will be chosen
carryOverRule = maxConfidence

; Default bounding box sizes (for conversion of point predictions to bounding boxes)
defaultBoxSize_w = 100
defaultBoxSize_h = 100



[AIController]
; Type of data to provide to model. One of 'images' (on disk) or 'features' (stored in database)
modelInput = images

; URL for the job scheduler broker
broker_URL = pyamqp://aiLabelUser:aiLabelPassword@kuduvm.westus2.cloudapp.azure.com:5672/rabbitmq_vhost
result_backend = rpc://aiLabelUser:aiLabelPassword@kuduvm.westus2.cloudapp.azure.com:5672/rabbitmq_vhost


; Python package path of the model to use
model_lib_path = ai.models.pytorch.detection.retinanet.RetinaNet

; Path to the options file of the model to use (file in JSON format)
model_options_path = ''

; Python package path of the AL criterion model to use
al_criterion_lib_path = ai.al.builtins.breakingties.BreakingTies

; Options for the AL criterion model (file in JSON format)
al_criterion_options_path = ''

; Maximum number of images to train model on at a time (otherwise takes latest annotations)
maxNumImages_train = 1024

; Maximum number of images to do inference at a time
maxNumImages_inference = 1024



[FileServer]
staticfiles_dir = /datadrive/hfaerialblobs/bkellenb/predictions/windowCropping/images
staticfiles_uri = /files



[Database]
; General DB properties
name = ailabeltooldb
schema = aerialelephants_wc
host = kuduvm.westus2.cloudapp.azure.com
port = 5432
user = ailabeluser
password = aiLabelUser

; Admin user for the project (stored within DB)
adminName = admin
adminEmail = admin@anonymous.com
adminPassword = bPbt]PebSq(,63\$

; Maximum number of (concurrent) connections per server instance
max_num_connections = 2